# Default values for grafana-agent.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
image:
  # -- Grafana Agent image
  repository: grafana/agent
  # -- Image pull policy
  pullPolicy: IfNotPresent
  # -- Overrides the image tag whose default is the chart appVersion.
  tag: ""

# -- Pull secret for private repository
imagePullSecrets: []
# -- Release name override
nameOverride: ""
# -- Full name overrie for release
fullnameOverride: ""

# -- Extra Volume mounts
extraVolumeMounts: []
# Scrape k8s logs
  # - name: containers
  #   mountPath: /var/lib/docker/containers
  #   readOnly: true
  #- name: pods
  #  mountPath: /var/log/pods
  #  readOnly: true

# -- Extra Volumes
extraVolumes: []
# Scrape k8s logs
  #- name: containers
  #  hostPath:
  #    path: /var/lib/docker/containers
  #- name: pods
  #  hostPath:
  #    path: /var/log/pods

# -- Number of replicas of Grafana Agent deployment (only relevant for service scraping mode)
replicaCount: 3

# -- Update strategy
updateStrategy: Recreate

serviceAccount:
  # -- Specifies whether a service account should be created
  create: true
  # -- Annotations to add to the service account
  annotations: {}
  # -- The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# -- Pod annotations
podAnnotations: {}

# -- Pod Security Context
podSecurityContext: {}
  # fsGroup: 2000

# -- Container Security Context
# @default -- see values.yaml
securityContext:
  privileged: true
  runAsUser: 0

service:
  # -- Service Type
  type: ClusterIP
  # -- Kubernetes service port
  port: 80

# -- Kubernetes pod resources
resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# -- Pod node selector
nodeSelector: {}

# -- Pod tolerations
tolerations:
  - effect: NoSchedule
    operator: Exists

# -- Affinity rules
affinity: {}

# Currently only supports Prometheus 'configs'.
# Other telemetary options will be added overtime.
config:
  # -- Server log_level
  logLevel: info
  # -- An existing ConfigMap entity that already exists, or is deployed by a parent chart.
  # Populate this to provide an existing config for Grafana Agent. This disables the charts configMap.
  existingConfigMap: ""
  loki:
    # -- Enable Loki config
    enabled: true
    # -- Loki config content
    # @default -- see values.yaml
    configs: |
      positions_directory: /tmp/loki-positions
      configs:
      - name: default
        clients:
          - url: http://localhost:3100/loki/api/v1/push
        scrape_configs:
        - job_name: system
          static_configs:
          - targets: ['localhost']
            labels:
              job: varlogs
              __path__: /var/log/*log
  tempo:
    # -- Enable Tempo config
    enabled: true
    # -- Tempo config content
    # @default -- see values.yaml
    configs: |
      - name: default
        receivers:
          jaeger:
            protocols:
              thrift_http:
        attributes:
          actions:
          - action: upsert
            key: env
            value: prod
        remote_write:
          - endpoint: tempo:55680
            insecure: true
        batch:
          timeout: 5s
          send_batch_size: 100
        automatic_logging:
          backend: loki
          loki_name: default
          spans: true
          processes: true
          roots: true
  prometheus:
    # -- Enable Prometheus config
    enabled: true
    # -- Directory mount point for Grafana Agent WAL
    walDir: /var/lib/agent/data
    # -- Global scrape interval
    scrapeInterval: 15s
    # -- External labels
    externalLabels: {}
    remoteWrite:
      # -- URL for the upstream federated Prometheus / Cortex instance
      url: http://cortex.default.svc.cluster.local
      # -- Remote write username/password
      auth:
        # username: ""
        # password: ""
    # -- Scrape configs / General configs for the Prometheus scraping
    # @default -- see values.yaml
    configs: |
      - name: agent
        remote_write:
          - url: {{ .Values.config.prometheus.remoteWrite.url }}
            {{- if .Values.config.prometheus.remoteWrite.auth }}
            basic_auth:
                password: {{ .Values.config.prometheus.remoteWrite.auth.password }}
                username: {{ .Values.config.prometheus.remoteWrite.auth.username }}
            {{- end }}
            headers:
              X-Scope-OrgID: fake
        scrape_configs:
          - job_name: local_scrape
            static_configs:
              - targets: ['127.0.0.1:12345']
                labels:
                  cluster: 'docker_compose'
                  container: 'agent'
                  pod: 'grafana-agent-local'

# Enables separation of ConfigMap for Agent expectations
# Also enables Consul for hash ring
scrapingServiceMode:
  # -- Enabled scraping service mode. See below for more details
  enabled: false

# -- Configure consul subchart resp. dependency chart
# @default -- see values.yaml
# Only deployed when scrapingServiceMode.enabled is true
consul:
  client:
    enabled: false
  dns:
    enabled: false
  server:
    replica: 3
  ui:
    enabled: false
  nodeSelector:
    role: server
